#Python 
#PyTorch

# What is TorchServe...?


> 開発者は、モデル開発にさまざまなオープンソースフレームワークを使用します。ここ数年、PyTorch は、ML を利用したアプリケーションを開発する多くの研究者、開発者、およびデータサイエンティストが選択する深層学習のフレームワークとなっています。PyTorch は、そのシンプルさに加えて、Python 的な方法でモデルを実装およびトレーニングでき、Eager モードと Graph モードをシームレスに切り替える機能があることから好まれています。しかしながら、これまで、PyTorch モデルを本番環境で大規模に提供することについて、簡単かつネイティブにサポートされた方法はありませんでした。PyTorch モデルを TorchScript を使用して Eager モードまたは Graph モードでデプロイし、複数のモデルを同時に提供し、A/B テスト用に本番モデルをバージョン管理し、モデルを動的にロードおよびアンロードし、詳細なログとカスタマイズ可能なメトリクスを監視できます。TorchServe は使いやすいです。ローカルにデプロイするのに便利な CLI が付属しており、コンテナにパッケージ化して [Amazon SageMaker](https://aws.amazon.com/sagemaker/) または [Amazon EKS](https://aws.amazon.com/eks/) で簡単にスケールアウトできます。画像分類、オブジェクト検出、画像セグメンテーション、テキスト分類などの一般的な問題のデフォルトハンドラーを使用して、数行のコードでデプロイできます。初期化、前処理、後処理用の長いサービスハンドラーを記述する必要はありません。TorchServe はオープンソースです。つまり、完全にオープンであり、デプロイのニーズに合わせて拡張できます。

つまり何ができるかと言うと、`Torch`で実装されたモデル＋リクエスト処理を統合し、デプロイまでの時間を短縮してくれるもの。
機械学習エンジンのデプロイのような用途に最適。
ただし、`Webアプリ` + `Docker` + `GCP`の理解が求められ、概念としても一般的に知られるものではないので学習コストは高いかも...?
(ちなみに有名ライブラリは基本`/GCP` 以下にデプロイ用の設定ファイルなどがあることが多い。`Yolov5`の場合、`GAE` にデプロイするようの`app.yaml`  が用意されている)

`TorchServe` の概念については以下図を参考にされたい。

![TorchServe](https://cdn-ak.f.st-hatena.com/images/fotolife/t/takaherox/20200726/20200726152512.png)

## TorchServeの構成

TorchServeは次の要素で構成される。

- `Frontend`
	- 基本的にリクエストとレスポンスを制御する
	- Interface APIを定義してエンドポイントを作成する
	- モデルと呼ばれる
	- 複数のモデルを複数のエンドポイントとして定義することが出来る
	- モデルのライフサイクル（初期化、終了のタイミング）を管理
- `Backend`
	- Model Worker
		- モデル推論を行い、実行時にはインスタンス化される
		- ひとつまたは複数の`Worker Proccess` から構成される
	- Model
		- NNの内部構造を辞書型で定義した`state_dict` などのモデルアーティファクトとともに、データに対してカスタマイズされた前処理や後処理を提供する。
		- モデルはクラウドストレージやローカルホストからもインポート出来る。
- `Other`
	- Plugin
		- TorchServeの起動時に利用者によってカスタマイズされたエンドポイントや認証認可を指定できる。（Artifact RegistryなどのGCPサービスを使用する場合はあまり使わない）
	- Model Store
		- 読み込み可能なモデル（`.pt`, `.plt`ファイル）のディレクトリを指定する（重要！）
- `Mangement API` & `Process Otherstration`

## 参考

- [公式TorchServe(英語版)](https://pytorch.org/serve/)
- [TorchServe入門](https://takaherox.hatenablog.com/entry/2021/01/02/144216)